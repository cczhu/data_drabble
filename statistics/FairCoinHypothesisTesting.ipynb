{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian vs. Frequentist Fair Coin Hypothesis Testing\n",
    "\n",
    "We answer whether a coin is fair or not based on a coin-flip experiment using Bayesian and Frequentist hypothesis testing methodologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import scipy.special as sps\n",
    "import numpy as np\n",
    "\n",
    "# Follows https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter1_Introduction/Ch1_Introduction_PyMC3.ipynb\n",
    "def coin_flipper(N, pi=0.5, seed=42):\n",
    "    \"\"\"Returns a coin flip, where 1 is heads and 0 is tails.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        Number of flips in the experiment.\n",
    "    pi : float in [0, 1], optional.\n",
    "        The probability of the coin returning heads.  Default: 0.5.\n",
    "    seed : None or int or `np.random.RandomState` instance, optional\n",
    "        Seed value.  Default: 42.\n",
    "    \"\"\"\n",
    "    return stats.bernoulli.rvs(pi, size=N, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Methodology\n",
    "\n",
    "Following [these lecture notes](http://idiom.ucsd.edu/~rlevy/lign251/fall2007/lecture_9.pdf) from [Roger Levy's Linguistics 251 course](http://idiom.ucsd.edu/~rlevy/lign251/fall2007/), let us set up two hypotheses, $H_f$ that the coin is fair, and $H_{uf}$ that it is unfair.  Assume our data is $\\vec{x}$.  Then\n",
    "\n",
    "\\begin{eqnarray}\n",
    "P(H_f|\\vec{x}) &=& \\frac{P(\\vec{x}|H_f)P(H_f)}{P(\\vec{x})} \\\\\n",
    "P(H_{uf}|\\vec{x}) &=& 1 - P(H_f|\\vec{x})\n",
    "\\end{eqnarray}\n",
    "\n",
    "Moreover, we must marginalize over the possible hypotheses:\n",
    "\n",
    "$$\n",
    "P(\\vec{x}) = P(\\vec{x}|H_f)P(H_f) + P(\\vec{x}|H_{uf})P(H_{uf})\n",
    "$$\n",
    "\n",
    "To use these equations, we'll need to specify the hypotheses and their probabilities.  Take $\\pi$ to be probability of heads (more generally the Bernoulli parameter).  Then, for $H_f$, we have $P(\\pi|H_f) = 1$ if $\\pi = 0.5$ and $P(\\pi|H_f) = 0$ if $\\pi \\neq 0.5$. Then:\n",
    "\n",
    "$$\n",
    "P(\\vec{x}|H_f) = \\sum_i P(\\vec{x}|\\pi_i)P_{H_f}(\\pi_i) = P(\\vec{x}|\\pi_i = 0.5) = {n\\choose n_\\mathrm{heads}}\\frac{1}{2^n}\n",
    "$$\n",
    "\n",
    "Where we have used the fact that $P(\\vec{x}|\\pi_i) =  {n\\choose n_\\mathrm{heads}} \\pi^{n_\\mathrm{heads}}(1 - \\pi)^{n_\\mathrm{tails}}$.\n",
    "\n",
    "For $H_{uf}$ we run into a problem, since we'd likely want to assume $\\pi \\in [0, 1]$ (and is thus uniformly distributed), and is equally likely to take on any value within that range.  In that case:\n",
    "\n",
    "$$\n",
    "P(\\vec{x}|H_{uf}) = \\sum_i P(\\vec{x}|\\pi_i)P_{H_{uf}}(\\pi_i) = \\int_0^1 P(\\vec{x}|\\pi_i)P(\\pi_i)d\\pi\n",
    "$$\n",
    "\n",
    "$P(\\pi_i) = 1$ for a uniform RV about $[0, 1]$, and $P(\\vec{x}|\\pi_i)$ is the same as from above.  As it turns out, the following relation holds:\n",
    "\n",
    "$$\n",
    "\\int_0^1 \\pi^{a}(1 - \\pi)^{b}d\\pi = \\frac{\\Gamma(a + 1)\\Gamma(b + 1)}{\\Gamma(a + b + 2)} = \\frac{a!b!}{(a + b + 1)!}\n",
    "$$\n",
    "\n",
    "Where $\\Gamma$ is the usual [Gamma function](https://en.wikipedia.org/wiki/Gamma_function).  This simplifies cancels with the ${n\\choose n_\\mathrm{heads}}$ and thus,\n",
    "\n",
    "$$\n",
    "P(\\vec{x}|H_{uf}) = \\frac{1}{n_\\mathrm{heads} + n_\\mathrm{tails} + 1}\n",
    "$$\n",
    "\n",
    "Assuming we have no prior information, $P(H_f) = P(H_{uf}) = 0.5$.  In cases like this where both hypotheses have equally likely priors, we can use the [Bayes factor](https://en.wikipedia.org/wiki/Bayes_factor), the ratio of likelihoods between two hypotheses, to determine which to favour.  (In cases where there are multiple hypotheses with equal priors, we would take the maximum among them, which would have the highest Bayes factor when compared against any other hypothesis.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_xhf(heads, tails):\n",
    "    return sps.comb(heads + tails, heads) / 2.**(heads + tails)\n",
    "\n",
    "def get_prob_xhuf(heads, tails):\n",
    "    return float(heads + tails + 1)**(-1)\n",
    "\n",
    "def get_cointoss_bayesian(experiment):\n",
    "    \"\"\"Determine whether the coin is fair using Bayesian hypothesis testing.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    experiment : list-like\n",
    "        Output from `coin_flipper`.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    prob_hf : float\n",
    "        Probability the coin is fair.\n",
    "    bayes_factor : float\n",
    "        Bayes factor P(H_f) / P(H_uf).    \n",
    "    \"\"\"\n",
    "    heads = np.sum(experiment)\n",
    "    tails = len(experiment) - heads\n",
    "    prob_xhf = get_prob_xhf(heads, tails)\n",
    "    prob_xhuf = get_prob_xhuf(heads, tails)\n",
    "    prob_hf = prob_xhf / (prob_xhf + prob_xhuf)\n",
    "    return prob_hf, prob_xhf / prob_xhuf\n",
    "\n",
    "def print_cointoss_bayesian(experiment, name):\n",
    "    print(\"Experiment {0} - heads/all: {1:d}/{2:d} = {3:.2f},\"\n",
    "          \" P(H_f): {4:.4f}, Bayes Factor: {5:.4f}\"\n",
    "          .format(name, np.sum(experiment), len(experiment),\n",
    "                  np.sum(experiment)/len(experiment), \n",
    "                  *get_cointoss_bayesian(experiment)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_f1 = coin_flipper(30, pi=0.5, seed=42)\n",
    "experiment_f2 = coin_flipper(787, pi=0.5, seed=584)\n",
    "experiment_uf1 = coin_flipper(27, pi=0.34, seed=56)\n",
    "experiment_uf2 = coin_flipper(491, pi=0.59, seed=26854)\n",
    "experiment_uf3 = coin_flipper(787, pi=0.55, seed=455)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment F1 - heads/all: 13/30 = 0.43, P(H_f): 0.7757, Bayes Factor: 3.4576\n"
     ]
    }
   ],
   "source": [
    "print_cointoss_bayesian(experiment_f1, \"F1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment F2 - heads/all: 385/787 = 0.49, P(H_f): 0.9491, Bayes Factor: 18.6507\n"
     ]
    }
   ],
   "source": [
    "print_cointoss_bayesian(experiment_f2, \"F2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment UF1 - heads/all: 10/27 = 0.37, P(H_f): 0.6377, Bayes Factor: 1.7599\n"
     ]
    }
   ],
   "source": [
    "print_cointoss_bayesian(experiment_uf1, \"UF1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment UF2 - heads/all: 292/491 = 0.59, P(H_f): 0.0026, Bayes Factor: 0.0026\n"
     ]
    }
   ],
   "source": [
    "print_cointoss_bayesian(experiment_uf2, \"UF2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment UF3 - heads/all: 442/787 = 0.56, P(H_f): 0.0533, Bayes Factor: 0.0564\n"
     ]
    }
   ],
   "source": [
    "print_cointoss_bayesian(experiment_uf3, \"UF3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in cases where \n",
    "\n",
    "https://www.annualreviews.org/doi/full/10.1146/annurev-statistics-031017-100307\n",
    "\n",
    "http://idiom.ucsd.edu/~rlevy/lign251/fall2007/lecture_7.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
